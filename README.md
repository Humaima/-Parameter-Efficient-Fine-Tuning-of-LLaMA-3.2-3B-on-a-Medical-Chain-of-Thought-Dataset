# -Parameter-Efficient-Fine-Tuning-of-LLaMA-3.2-3B-on-a-Medical-Chain-of-Thought-Dataset
This project demonstrates parameter-efficient fine-tuning (PEFT) of the LLaMA 3.2 (3B) model using LoRA (Low-Rank Adaptation) on a Medical Chain-of-Thought (CoT) dataset.
